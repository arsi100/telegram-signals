I understand your frustration after struggling with this deployment for months. Let me help you systematically solve this once and for all. Here's the step-by-step plan:

### 1. First, Let's Verify the Local Setup
Before redeploying, we need absolute certainty the code works locally. Run this minimal test script:

```python
# test_bybit_ws.py
import asyncio
from pybit.unified_trading import WebSocket
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def handle_message(msg):
    logger.info(f"Received: {msg}")

async def main():
    ws = WebSocket(
        testnet=True,  # Test with testnet first!
        channel_type="linear"
    )
    
    # Subscribe to single symbol
    ws.ticker_stream(
        symbol="BTCUSDT", 
        callback=handle_message
    )
    
    # Keep connection alive
    while True:
        await asyncio.sleep(1)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("Stopped by user")
```

Run with:
```bash
python test_bybit_ws.py
```

### 2. If Local Test Works, Nuclear Redeployment
If the test works, follow this deployment procedure:

```bash
# 1. Delete all old services and images
gcloud run services delete micro-scalp-ingestion --region=us-central1 --quiet
gcloud container images delete us-central1-docker.pkg.dev/telegram-signals-205cc/cloud-run-source-deploy/micro-scalp --force-delete-tags --quiet

# 2. Fresh build with cache busting
TIMESTAMP=$(date +%s)
echo "# Cache bust $TIMESTAMP" >> Dockerfile.unified
gcloud builds submit --config cloudbuild-micro.yaml --substitutions=_TAG=cleanbuild-$TIMESTAMP

# 3. Deploy fresh
gcloud run deploy micro-scalp-ingestion \
  --image=us-central1-docker.pkg.dev/telegram-signals-205cc/cloud-run-source-deploy/micro-scalp:cleanbuild-$TIMESTAMP \
  --region=us-central1 \
  --no-allow-unauthenticated \
  --set-env-vars="SERVICE_TYPE=ingestion" \
  --min-instances=1 \
  --memory=512Mi
```

### 3. Critical Verification
Check logs with:
```bash
gcloud logging read "resource.type=cloud_run_revision" --limit=50 --format="value(textPayload)" | grep -E "(Starting|Subscribed|Published|Error)"
```

### If Still Failing
1. Check your Cloud Run IAM roles:
```bash
gcloud projects get-iam-policy telegram-signals-205cc --flatten="bindings[].members" --filter="bindings.role:roles/run.admin"
```

2. Verify service account:
```bash
gcloud iam service-accounts list --project=telegram-signals-205cc
```

### Alternative Approach
If still stuck, let's try a completely different deployment method:

1. Create fresh GCP project
2. Deploy just the ingestion service first
3. Use a more basic Dockerfile:
```dockerfile
FROM python:3.9-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["python", "-u", "micro_scalp_engine/data_ingestion.py"]
```

Would you like me to:
1. Explain any part in more detail?
2. Provide the complete corrected service code?
3. Walk through setting up a fresh GCP project?

The key is starting fresh with verified working code. Your persistence will pay off - we're very close to solving this.